{
 "metadata": {
  "name": "",
  "signature": "sha256:9ca2faaf39744b181d8e9cad36156b932f2e9da595dec04b22227dfe939ddbe5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Doing Naive Bayes Classification (On Softcore Porn)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is basically an example of going from raw labeled text to classification, first with NLTK and then Sklearn.\n",
      "\n",
      "I farmed out (badly formatted) chunks of 50 Shades of Gray to Mechanical Turkers to rate as \"sexy\" or \"not\" (actually only a ratings scale)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At this point, the Turkers review and score the file - 2 reviewers, and I avg their scores. Load scored data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename = '50ShadesData/fifty-shades-scores_text.txt'\n",
      "fiftyfields = [doc.split('\\t') for doc in open(filename,'r')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fiftyfields[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 102,
       "text": [
        "['label', 'text', 'Answer1', 'Answer2', 'Avg\\r\\n']"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fiftyfields[3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 103,
       "text": [
        "['fifty_500_224',\n",
        " '\"* Miss Steele ? * the courier asks. I frown questioningly at Mr. Clayton , who shrugs , as puzzled as me. My heart sinks. What has Christian sent me now ? I sign for the small package and open it immediately. It * s a BlackBerry. My heart sinks further. I switch it on . From : Christian Grey Subject : BlackBerry ON LOAN Date : May 27 2011 11 : 15 To : Anastasia Steele I need to be able to contact you at all times , and since this is your most honest form of communication , I figured you needed a BlackBerry . Christian Grey CEO , Grey Enterprises Holdings , Inc . From : Anastasia Steele Subject : Consumerism Gone Mad Date : May 27 2011 13 : 22 To : Christian Grey I think you need to call Dr. Flynn right now . Your stalker tendencies are running wild . I am at work. I will e-mail you when I get home . Thank you for yet another gadget . I wasn * t wrong when I said you were the ultimate consumer . Why do you do this ? Ana From : Christian Grey Subject : Sagacity from One So Young Date : May 27 2011 13 : 24 To : Anastasia Steele Fair point well made , as ever , Miss Steele . Dr. Flynn is on vacation . And I do this because I can . Christian Grey CEO , Grey Enterprises Holdings , Inc . I put the thing in my back pocket , hating it already. E-mailing Christian is addictive , but I am supposed to be working. It buzzes once against my behind * How apt , I think ironically , but summoning all my willpower , I ignore it . At four , Mr. and Mrs. Clayton gather all the other employees in the shop and , during a hair-curlingly embarrassing speech , present me with a check for three hundred dollars. In that moment , all the events from the past three weeks well up inside of me : exams , graduation , an intense , fucked-up billionaire , deflowering , hard and soft limits , playrooms with no consoles , helicopter rides , and the fact that I will move tomorrow. Amazingly , I hold myself together. My subconscious is in awe. I hug the Claytons hard . They have been kind and generous employers , and I will miss them . KATE IS CLIMBING OUT of her car when I arrive home . * What * s that ? * she says accusingly , pointing at the Audi. I can * t resist . * It * s a car , * I quip. She narrows her eyes , and for a brief moment , I wonder if she * s going to put me across her knee , too. * My graduation present. * I try to act nonchalant. Yes , I get\"',\n",
        " '0',\n",
        " '1',\n",
        " '0.5\\r\\n']"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Score of 0 is \"not a sex scene\", while \"1\" and \"2\" are increasing in steaminess, and \"3\" is definitely a sex scene. (In later scoring, I reduced the options to just 3.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# code the snippets are either \"yes\" or \"no\" \n",
      "fiftyyes = [x for x in fiftyfields[1:] if float(x[4]) >= 2.5]\n",
      "fiftyno = [x for x in fiftyfields[1:] if float(x[4]) < 2.5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(fiftyyes), len(fiftyno)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "86 296\n"
       ]
      }
     ],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#fiftyyes[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outputfile = '50ShadesData/fifty_labeled_texts.txt'\n",
      "with file(outputfile, 'w') as handle:\n",
      "    for row in fiftyyes:\n",
      "        handle.write(row[0] + \"\\t\" + row[1] + \"\\t\" + \"yes\\n\")\n",
      "    for row in fiftyno:\n",
      "        handle.write(row[0] + \"\\t\" + row[1] + \"\\t\" + \"no\\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_documents_csv(filename):\n",
      "    # assume label is cell 1, doc text is cell 2, classification is cell 3\n",
      "    labels = []\n",
      "    documents = []\n",
      "    classif = []\n",
      "    for line in open(filename):\n",
      "        fields = line.split(\"\\t\")\n",
      "        if fields[0].strip != 'label':    # header row\n",
      "            documents.append(fields[1].strip())\n",
      "            labels.append(fields[0].strip())\n",
      "            if fields[2]:\n",
      "                classif.append(fields[2].strip(\"\\n\"))\n",
      "    print \"got \", len(documents)\n",
      "    return (documents, labels, classif)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "docs, labels, classes = get_documents_csv(outputfile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "got  382\n"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## I did do some simple cluster analysis on it, btw (elsewhere)- colored labels by green = yes, red = no. This suggests I can build a classifier!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src='files/sex_scenes_hierarchical.png'>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###But let's build a classifier.  From here, use Jacob Perkins' example for how to use the nltk classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this text can't be used as is in the classifier:\n",
      "docs[250]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 113,
       "text": [
        "'\"sort of gliding ? * I nod . * Wow. * She * s speechless * a novel concept for my mother. She gapes at me , but eventually recovers herself and resumes her original line of questioning . * How was last night ? Did you talk ? * Jeez. I flush bright scarlet . * We talked * last night and today. It * s getting better. * * Good. * She turns her attention back to the four cookbooks she has open on the kitchen table . * Mom * if you like , I * ll cook this evening. * * Oh , honey , that * s kind of you , but I want to do it. * * Okay. * I grimace , knowing full well that my mother * s cooking is pretty hit or miss. Perhaps she * s improved since she moved to Savannah with Bob. There was a time I wouldn * t subject anyone to her cooking * even * who do I hate ? Oh yes * Mrs. Robinson * Elena. Well , maybe her. Will I ever meet this damned woman ? I decide to send a quick thank-you to Christian . From : Anastasia Steele Subject : Soaring as Opposed to Sore-ing Date : June 2 2011 10 : 20 EST To : Christian Grey Sometimes , you really know how to show a girl a good time . Thank you Ana x From : Christian Grey Subject : Soaring vs Sore-ing Date : June 2 2011 10 : 24 EST To : Anastasia Steele I * ll take either of those over your snoring. I had a good time , too . But I always do when I * m with you . Christian Grey CEO , Grey Enterprises Holdings , Inc . From : Anastasia Steele Subject : SNORING Date : June 2 2011 10 : 26 EST To : Christian Grey I DO NOT SNORE. And if I do , it * s very ungallant of you to point it out . You are no gentleman , Mr. Grey ! And you are in the Deep South , too ! Ana From : Christian Grey Subject : Somniloquy Date : June 2 2011 10 : 28 EST To : Anastasia Steele I have never claimed to be a gentleman , Anastasia , and I think I have demonstrated that point to you on numerous occasions. I am not intimidated by your SHOUTY capitals. But I will confess to a small white lie : no * you don * t snore , but you do talk. And it * s fascinating . What happened to my kiss ? Christian Grey Cad & CEO , Grey Enterprises Holdings , Inc . Holy shit. I know I talk in my sleep. Kate has told me enough times. What the hell have I said ? Oh no . From : Anastasia Steele Subject : Spill the Beans\"'"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Document:\n",
      "    def __init__(self):\n",
      "        Document.words = []\n",
      "        Document.original = \"\"\n",
      "        Document.clean = \"\"\n",
      "        Document.label = \"\"\n",
      "        Document.classif = \"\"\n",
      "\n",
      "def clean_doc(doc):\n",
      "    from nltk import corpus \n",
      "    import re\n",
      "    stopwords = corpus.stopwords.words('english')\n",
      "    new = Document()\n",
      "    new.original = doc\n",
      "    sentence = doc\n",
      "    sentence = sentence.lower()\n",
      "    # note that I'm looking for non-numeric alphabetic items; this makes a difference from sklearn\n",
      "    words = words = re.findall(r'\\w+', sentence,flags = re.UNICODE | re.LOCALE)\n",
      "    new.clean = \" \".join(words)\n",
      "    words = [word for word in words if word not in stopwords]\n",
      "    new.words = words\n",
      "    return new"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clean_doc(docs[14]).clean"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 115,
       "text": [
        "'it s delicious christian and i look up at each other at the same time with relief i giggle and he cocks his head to one side that s a lovely sound he murmurs why have you never had vanilla sex before have you always done er what you ve done i ask intrigued he nods slowly sort of his voice is wary he frowns for a moment and seems to be engaged in some kind of internal struggle then he glances up a decision made one of my mother s friends seduced me when i was fifteen oh holy shit that s young she had very particular tastes i was her submissive for six years he shrugs oh my brain has frozen stunned into inactivity by this admission so i do know what it involves anastasia his eyes glow with insight i stare at him unable to articulate anything even my subconscious is silent i didn t really have a run of the mill introduction to sex curiosity kicks in big time so you never dated anyone at college no he shakes his head to emphasize the point the waitress takes our bowls interrupting us for a moment why i ask when she s gone he smiles sardonically do you really want to know yes i didn t want to she was all i wanted needed and besides she d have beaten the shit out of me he smiles fondly at the memory oh this is way too much information but i want more so if she was a friend of your mother s how old was she he smirks old enough to know better do you still see her yes do you still er i flush no he shakes his head and smiles indulgently at me she s a very good friend oh does your mother know he gives me a don t be stupid stare of course not the waitress returns with venison but my appetite has vanished what a revelation christian the submissive holy shit i take a large slug of pinot grigio he s right of course it s delicious jeez all these revelations it s so much to think about i need time to process this when i m on my own not when i m distracted by his'"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clean_docs = [clean_doc(x) for x in docs]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def add_ids_classes(doc_objs, labels, classes):\n",
      "    for i,x in enumerate(doc_objs):\n",
      "        x.label = labels[i]\n",
      "        x.id = i\n",
      "        x.classif = classes[i]\n",
      "    return doc_objs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clean_docs = add_ids_classes(clean_docs, labels, classes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clean_docs[0]\n",
      "#clean_docs[0].classif"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "neg_docs = [doc for doc in clean_docs if doc.classif == 'no']\n",
      "pos_docs = [doc for doc in clean_docs if doc.classif == 'yes']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(neg_docs), len(pos_docs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "296 86\n"
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Bag of Words - just t/f\n",
      "def word_feats(words):\n",
      "        return dict([(word, True) for word in words])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "neg_words = [(word_feats(doc.words),'neg') for doc in neg_docs]\n",
      "#neg_words = [flatten_dictlist(neg_words)]\n",
      "pos_words = [(word_feats(doc.words),'pos') for doc in pos_docs]\n",
      "negcutoff = len(neg_words)*3/4\n",
      "poscutoff = len(pos_words)*3/4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_fic = neg_words[:negcutoff] + pos_words[:poscutoff]\n",
      "test_fic = neg_words[negcutoff:] + pos_words[poscutoff:]\n",
      "print 'train on %d instances, test on %d instances' % (len(train_fic), len(test_fic))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train on 286 instances, test on 96 instances\n"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk.classify.util\n",
      "from nltk.classify import NaiveBayesClassifier\n",
      "classifier = NaiveBayesClassifier.train(train_fic)\n",
      "print 'accuracy:', nltk.classify.util.accuracy(classifier, test_fic)\n",
      "classifier.show_most_informative_features(15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.822916666667\n",
        "Most Informative Features\n",
        "                   groan = True              pos : neg    =     27.9 : 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "               sensation = True              pos : neg    =     26.3 : 1.0\n",
        "                  rhythm = True              pos : neg    =     26.3 : 1.0\n",
        "                   lifts = True              pos : neg    =     24.0 : 1.0\n",
        "                 panting = True              pos : neg    =     22.6 : 1.0\n",
        "                   navel = True              pos : neg    =     21.7 : 1.0\n",
        "                   eases = True              pos : neg    =     21.7 : 1.0\n",
        "                  orgasm = True              pos : neg    =     21.7 : 1.0\n",
        "                grasping = True              pos : neg    =     19.4 : 1.0\n",
        "                  smooth = True              pos : neg    =     19.4 : 1.0\n",
        "                  packet = True              pos : neg    =     19.4 : 1.0\n",
        "                heavenly = True              pos : neg    =     19.4 : 1.0\n",
        "                    moan = True              pos : neg    =     19.1 : 1.0\n",
        "                 breasts = True              pos : neg    =     18.5 : 1.0\n",
        "                  loudly = True              pos : neg    =     17.2 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "An interface to Sklearn from NLTK is available (see Perkin's Python 3 and NLTK book from Packt)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.classify.scikitlearn import SklearnClassifier\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from nltk.classify.util import accuracy\n",
      "sk_classifier = SklearnClassifier(MultinomialNB())\n",
      "sk_classifier.train(train_fic)\n",
      "accuracy(sk_classifier, test_fic)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 126,
       "text": [
        "0.8958333333333334"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Perkins discusses the difference in implementations in his book."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Moving to SciKit Learn W/O the interface"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For scikit learn, it's convenient to have the chunks as docs in separate directories based on their classification."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I moved the files by hand into separate directories, based on how I wrote them out above.  Make a \"yes\" and \"no\" subdirectory for the labeled files."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# If you want to load data into sklearn, put your text into directories named by the category 'labels' of the classification.\n",
      "bunchf = load_files('50ShadesData/fiftyshades_yesno/', categories=['yes','no'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bunchf.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 129,
       "text": [
        "['target_names', 'data', 'target', 'DESCR', 'filenames']"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(bunchf.data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 130,
       "text": [
        "382"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bunchf.filenames[0:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 131,
       "text": [
        "array(['50ShadesData/fiftyshades_yesno/no/no_fifty_500_77',\n",
        "       '50ShadesData/fiftyshades_yesno/no/no_fifty_500_239',\n",
        "       '50ShadesData/fiftyshades_yesno/yes/yes_fifty_500_328',\n",
        "       '50ShadesData/fiftyshades_yesno/yes/yes_fifty_500_208',\n",
        "       '50ShadesData/fiftyshades_yesno/no/no_fifty_500_30',\n",
        "       '50ShadesData/fiftyshades_yesno/no/no_fifty_500_183',\n",
        "       '50ShadesData/fiftyshades_yesno/yes/yes_fifty_500_114',\n",
        "       '50ShadesData/fiftyshades_yesno/no/no_fifty_500_17',\n",
        "       '50ShadesData/fiftyshades_yesno/yes/yes_fifty_500_92',\n",
        "       '50ShadesData/fiftyshades_yesno/no/no_fifty_500_15'], \n",
        "      dtype='|S52')"
       ]
      }
     ],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_data = bunchf.data  # assign all of it"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_target = bunchf.target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bunchf.target_names[bunchf.target[10]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 134,
       "text": [
        "'no'"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Split up the data into train and test using sklearn's cross-validation..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "# try changing the random_state - interesting differences in results.\n",
      "Xf_train, Xf_test, yf_train, yf_test = cross_validation.train_test_split(bunchf.data, \n",
      "                                                                         bunchf.target, \n",
      "                                                                         test_size=0.4, \n",
      "                                                                         random_state=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# I need a lemmatizer step because some of the text I used in one classification was in first person present tense\n",
      "from nltk import word_tokenize, wordpunct_tokenize\n",
      "from nltk.stem import WordNetLemmatizer\n",
      "from nltk.stem import PorterStemmer\n",
      "import string\n",
      "\n",
      "class LemmaTokenizer(object):\n",
      "    def __init__(self):\n",
      "        self.wnl = WordNetLemmatizer()\n",
      "        self.port = PorterStemmer()\n",
      "    def __call__(self, doc):\n",
      "        # or [self.wnl.lemmatize(t.lower())]\n",
      "        return [self.wnl.lemmatize(t.lower()) for t in word_tokenize(doc) if t not in string.punctuation and len(t) > 2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidfvec = TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words='english')\n",
      "vectors_train = tfidfvec.fit_transform(Xf_train)\n",
      "vectors_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 167,
       "text": [
        "(229, 6398)"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "import sklearn.metrics as metrics\n",
      "\n",
      "vectors_test = tfidfvec.transform(Xf_test)\n",
      "clf = MultinomialNB(alpha=.01)\n",
      "clf.fit(vectors_train, yf_train)\n",
      "pred = clf.predict(vectors_test)\n",
      "metrics.accuracy_score(yf_test, pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 178,
       "text": [
        "0.92810457516339873"
       ]
      }
     ],
     "prompt_number": 178
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Notice the accuracy is better than in NLTK."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# code for binary classification case posted here: http://stackoverflow.com/questions/11116697/how-to-get-most-informative-features-for-scikit-learn-classifiers\n",
      "def show_most_informative_features(vectorizer, clf, n=20):\n",
      "    feature_names = vectorizer.get_feature_names()\n",
      "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
      "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
      "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
      "        print \"\\t%.4f\\t %-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "show_most_informative_features(tfidfvec, clf, n=30)  # positive to the right, negative to left."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t-11.0355\t -nine-tails    \t\t-5.2681\thand           \n",
        "\t-11.0355\t 15.1           \t\t-5.3343\teye            \n",
        "\t-11.0355\t 15.10          \t\t-5.5503\twant           \n",
        "\t-11.0355\t 15.14          \t\t-5.6410\tfinger         \n",
        "\t-11.0355\t 15.19          \t\t-5.6462\tkiss           \n",
        "\t-11.0355\t 15.2           \t\t-5.6726\twhisper        \n",
        "\t-11.0355\t 15.21          \t\t-5.6891\tslowly         \n",
        "\t-11.0355\t 15.22          \t\t-5.7123\tmouth          \n",
        "\t-11.0355\t 15.24          \t\t-5.7394\tinside         \n",
        "\t-11.0355\t 15.3           \t\t-5.7508\thead           \n",
        "\t-11.0355\t 15.4           \t\t-5.7516\tgroan          \n",
        "\t-11.0355\t 15.5           \t\t-5.7806\tbody           \n",
        "\t-11.0355\t 15.6           \t\t-5.7922\tbed            \n",
        "\t-11.0355\t 15.7           \t\t-5.8000\tmurmur         \n",
        "\t-11.0355\t 15.8           \t\t-5.8131\tfeel           \n",
        "\t-11.0355\t 15.9           \t\t-5.8221\thair           \n",
        "\t-11.0355\t 165            \t\t-5.8672\tleg            \n",
        "\t-11.0355\t 180-degree     \t\t-5.8720\tpull           \n",
        "\t-11.0355\t 1891           \t\t-5.8980\tdon            \n",
        "\t-11.0355\t 1920s          \t\t-5.9188\thip            \n",
        "\t-11.0355\t 1950.          \t\t-5.9373\tanastasia      \n",
        "\t-11.0355\t 1999           \t\t-5.9413\tyes            \n",
        "\t-11.0355\t 4x4            \t\t-5.9520\ttongue         \n",
        "\t-11.0355\t 52.            \t\t-5.9529\tlip            \n",
        "\t-11.0355\t 612            \t\t-5.9760\tgently         \n",
        "\t-11.0355\t 612.           \t\t-6.0014\tgoing          \n",
        "\t-11.0355\t 95.            \t\t-6.0055\tbreathes       \n",
        "\t-11.0355\t aah            \t\t-6.0311\tlike           \n",
        "\t-11.0355\t abide          \t\t-6.0991\tbreathing      \n",
        "\t-11.0355\t ability        \t\t-6.1205\treach          \n"
       ]
      }
     ],
     "prompt_number": 184
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pipelines are the easiest way to run and check models in sklearn. You can do it step by step if you prefer (I don't). But it's harder to inspect your features this way."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "import numpy as np\n",
      "text_clf = Pipeline([('vect', TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words='english')), \n",
      "    ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_ = text_clf.fit(Xf_train,yf_train)  #using 50 Shades test data to train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predicted = text_clf.predict(Xf_test)  # this was 50 shades test data\n",
      "metrics.accuracy_score(yf_test, predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 173,
       "text": [
        "0.89542483660130723"
       ]
      }
     ],
     "prompt_number": 173
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From here, you can build and use a classifier yourself: just create a model using the data you want (train) and then input any new data you want to classify (test).  This is a semi-useful comparison chart from a couple years ago:\n",
      "<img src='files/sklearn-newsgroups.png'>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## FYI: A much better tutorial on text and sklearn: http://radimrehurek.com/data_science_python/"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##A tutorial on sentiment detection and scikit-learn https://marcobonzanini.wordpress.com/2015/01/19/sentiment-analysis-with-python-and-scikit-learn/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}